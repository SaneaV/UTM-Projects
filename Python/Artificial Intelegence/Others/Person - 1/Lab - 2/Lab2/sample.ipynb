{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Классификатор на основе критерия Байеса: Наивный Байес\n",
    "\n",
    "Концепция: Классификатор Наивный Байес использует теорему Байеса для вычисления вероятности каждого класса, предполагая независимость признаков (наивное предположение). Класс с наибольшей вероятностью назначается как результат классификации.\n",
    "\n",
    "\n",
    "Шаги реализации:\n",
    "\n",
    "1. Импортируем GaussianNB из sklearn.naive_bayes.\n",
    "2. Обучаем модель на тренировочных данных.\n",
    "3. Выполняем предсказание и оцениваем результаты.\n",
    "\n",
    "\n",
    "Код:"
   ],
   "id": "d23334ea29c17984"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Загрузка данных\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Обучение модели\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Оценка\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Точность:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Визуализация: Матрица ошибок\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=load_iris().target_names, yticklabels=load_iris().target_names)\n",
    "plt.title(\"Матрица ошибок: Наивный Байес\")\n",
    "plt.xlabel('Предсказанные метки')\n",
    "plt.ylabel('Истинные метки')\n",
    "plt.show()\n"
   ],
   "id": "ac14f7ecf092d9a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2. Классификатор на основе функций: Метод опорных векторов (SVM)\n",
    "\n",
    "Концепция: Метод опорных векторов (SVM) строит гиперплоскость, разделяющую данные на разные классы, оптимизируя разделительную границу между классами и минимизируя ошибки классификации.\n",
    "\n",
    "Шаги реализации:\n",
    "\n",
    "1. Импортируем SVC из sklearn.svm.\n",
    "2. Обучаем модель с помощью тренировочных данных.\n",
    "3. Выполняем предсказание и оцениваем результаты.\n",
    "\n",
    "Код:"
   ],
   "id": "a286919b24f101b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Используем только первые два признака для визуализации\n",
    "X_2D = X[:, :2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2D, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Обучение модели\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Оценка\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Точность:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Визуализация: Граница принятия решений\n",
    "h = .02  # шаг для сетки\n",
    "x_min, x_max = X_2D[:, 0].min() - 1, X_2D[:, 0].max() + 1\n",
    "y_min, y_max = X_2D[:, 1].min() - 1, X_2D[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "Z = svm_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.75)\n",
    "plt.scatter(X_2D[:, 0], X_2D[:, 1], c=y, edgecolors='k', marker='o', s=50)\n",
    "plt.title(\"Граница принятия решений: Метод опорных векторов\")\n",
    "plt.xlabel('Признак 1')\n",
    "plt.ylabel('Признак 2')\n",
    "plt.show()\n"
   ],
   "id": "d673d9badf5ee13f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3. Классификатор на основе правил принятия решений: Дерево решений\n",
    "\n",
    "Концепция: Классификаторы на основе дерева решений используют правила «если-то» для разбиения набора данных на подмножества. Дерево представляет собой иерархическую структуру, в которой каждый узел соответствует признаку, а листья - классам.\n",
    "\n",
    "Шаги реализации:\n",
    "\n",
    "1. Импортируем DecisionTreeClassifier из sklearn.tree.\n",
    "2. Обучаем модель на тренировочных данных.\n",
    "3. Выполняем предсказание и оцениваем результаты.\n",
    "\n",
    "Код:"
   ],
   "id": "afdef5bf3c3c6d7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# Обучение модели\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Оценка\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Точность:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Визуализация: Дерево решений\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(dt_model, filled=True, feature_names=load_iris().feature_names, class_names=load_iris().target_names, rounded=True)\n",
    "plt.title(\"Дерево решений\")\n",
    "plt.show()\n",
    "\n",
    "# Визуализация: Матрица ошибок\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=load_iris().target_names, yticklabels=load_iris().target_names)\n",
    "plt.title(\"Матрица ошибок: Дерево решений\")\n",
    "plt.xlabel('Предсказанные метки')\n",
    "plt.ylabel('Истинные метки')\n",
    "plt.show()\n"
   ],
   "id": "8ed351f7680784a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "4. Классификатор на основе деревьев: Случайный лес\n",
    "\n",
    "Концепция: Случайный лес строит множество деревьев решений, а затем объединяет их результаты для улучшения точности. Итоговая классификация определяется большинством голосов среди всех деревьев.\n",
    "\n",
    "Шаги реализации:\n",
    "\n",
    "1. Импортируем RandomForestClassifier из sklearn.ensemble.\n",
    "2. Обучаем модель на тренировочных данных.\n",
    "3. Выполняем предсказание и оцениваем результаты.\n",
    "\n",
    "Код:"
   ],
   "id": "bc5f64943c889f5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Обучение модели\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Оценка\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Точность:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Визуализация: Важность признаков\n",
    "feature_importances = rf_model.feature_importances_\n",
    "plt.barh(load_iris().feature_names, feature_importances)\n",
    "plt.title(\"Важность признаков: Случайный лес\")\n",
    "plt.xlabel('Важность')\n",
    "plt.show()\n",
    "\n",
    "# Визуализация: Матрица ошибок\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=load_iris().target_names, yticklabels=load_iris().target_names)\n",
    "plt.title(\"Матрица ошибок: Случайный лес\")\n",
    "plt.xlabel('Предсказанные метки')\n",
    "plt.ylabel('Истинные метки')\n",
    "plt.show()\n"
   ],
   "id": "3b18c6476fe9e3e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "5. Классификатор мета-метод: AdaBoost\n",
    "\n",
    "Концепция: AdaBoost комбинирует слабые классификаторы (обычно деревья решений небольшой глубины) и на каждой итерации перераспределяет вес данных, чтобы сосредоточиться на ошибочно классифицированных элементах.\n",
    "\n",
    "Шаги реализации:\n",
    "\n",
    "1. Импортируем AdaBoostClassifier из sklearn.ensemble.\n",
    "2. Обучаем модель на тренировочных данных.\n",
    "3. Выполняем предсказание и оцениваем результаты.\n",
    "\n",
    "Код:"
   ],
   "id": "9fbe09da3733b59d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Обучение модели\n",
    "ada_model = AdaBoostClassifier(n_estimators=50)\n",
    "ada_model.fit(X_train, y_train)\n",
    "y_pred = ada_model.predict(X_test)\n",
    "\n",
    "# Оценка\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Точность:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Визуализация: Ошибочные предсказания\n",
    "incorrect = (y_pred != y_test)\n",
    "plt.scatter(X_test[incorrect, 0], X_test[incorrect, 1], color='red', label=\"Ошибочные предсказания\")\n",
    "plt.scatter(X_test[~incorrect, 0], X_test[~incorrect, 1], color='blue', label=\"Правильные предсказания\")\n",
    "plt.title(\"Ошибочные предсказания: AdaBoost\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Визуализация: Матрица ошибок\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=load_iris().target_names, yticklabels=load_iris().target_names)\n",
    "plt.title(\"Матрица ошибок: AdaBoost\")\n",
    "plt.xlabel('Предсказанные метки')\n",
    "plt.ylabel('Истинные метки')\n",
    "plt.show()\n"
   ],
   "id": "d696b9b929c30565",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Оценка результатов\n",
    "\n",
    "Каждый алгоритм генерирует набор метрик, который позволяет оценить его производительность:\n",
    "\n",
    "1. Точность: процент верных предсказаний.\n",
    "2. Precision: точность для каждого класса, отражающая, насколько часто модель правильно идентифицирует класс.\n",
    "3. Recall: способность модели верно идентифицировать элементы класса.\n",
    "4. F1-Score: гармоническое среднее между precision и recall.\n",
    "5. Матрица ошибок: отображает, как классификатор справился с каждым классом.\n",
    "\n",
    "Заключение\n",
    "\n",
    "Финальные комментарии будут зависеть от производительности каждого алгоритма на определенном наборе данных. В целом:\n",
    "\n",
    "1. Классификаторы, основанные на деревьях и мета-методы, показывают высокую точность, благодаря их устойчивости к шуму и способности объединять несколько классификаторов.\n",
    "2. Наивный Байес работает хорошо с независимыми признаками, но его эффективность снижается при наличии коррелированных признаков.\n",
    "3. SVM эффективен на хорошо разделяемых данных, но может быть медленным на больших наборах данных."
   ],
   "id": "4489082b3e13318a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
